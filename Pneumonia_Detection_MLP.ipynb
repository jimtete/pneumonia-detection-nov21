{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pneumonia Detection",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPWJ8BR+T+YUMuzoOsUnRV9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimtete/pneumonia-detection-nov21/blob/main/Pneumonia_Detection_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id4VhRN0NhRA"
      },
      "source": [
        "#Connects notebook with google drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The below code is bash commands to get familiar with the PaaS that was given"
      ],
      "metadata": {
        "id": "oR6sKeGvRHi_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muom7PQjn60v"
      },
      "source": [
        "#Use ! to exit python cmd line and enter bash command line\n",
        "#Gets data on given gpu\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG8tFO4N6Tc2"
      },
      "source": [
        "!ls -l gdrive/MyDrive/\"Machine Learning 2021\"/train_images/RESIZED224 | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaUDyYWCBZW6"
      },
      "source": [
        "!rm gdrive/MyDrive/\"Machine Learning 2021\"/train_images/train_images/*RESIZED224.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqYBOpqoA-mz"
      },
      "source": [
        "!ls -l gdrive/MyDrive/\"Machine Learning 2021\"/test_images/test_images | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq_-O0N-DkQm"
      },
      "source": [
        "###First off we are starting by resizing the resolution for all the x-ray images into a 224x224.\n",
        "###This is getting done by using the PIL library with the\n",
        "```from PIL import Image, ImageDraw```\n",
        "\n",
        "```import glob as glob```\n",
        "\n",
        "```import os, sys```\n",
        "###comands.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvg8OBWQIj7B"
      },
      "source": [
        "##Importing the needed libraries for image data manipulation\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "import pandas as pd\n",
        "import os, sys\n",
        "import glob as glob\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvWn7NH5vmtq"
      },
      "source": [
        "###The code below is used to import all the vanilla x-ray images' names into a list.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Creating an empty list that will store all the image paths for the train set"
      ],
      "metadata": {
        "id": "8h21S0xGSLKZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz9kgL8iI-oB"
      },
      "source": [
        "##Creating a list that will include all the names of vanilla pictures.\n",
        "imageNamesList = []\n",
        "imagePath=\"gdrive/MyDrive/Machine Learning 2021/train_images/train_images/\"\n",
        "for filename in glob.glob(imagePath+\"*.jpg\"):\n",
        "  ##Append the file paths on the list.\n",
        "  imageNamesList.append(filename)\n",
        "\n",
        "##Seting the starting index for a test drive\n",
        "i = imageNamesList[1].rindex(\"/\")+1\n",
        "print(imageNamesList[1][i:])\n",
        "\n",
        "#Image.open(\"gdrive/MyDrive/Machine Learning 2021/train_images/train_images/img_1017234134520030571.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Resizing each image into the size vector bellow\n",
        "```size=224,224```\n",
        "\n",
        "####Change the vector into your prefered size\n"
      ],
      "metadata": {
        "id": "Tf1FnMZMSWpG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94x6cTesKuGk"
      },
      "source": [
        "size=224,224 ##We create a 2-index vector with our desired resolution for the pictures.\n",
        "\n",
        "##For each name we open the vanilla picture > resize it > save it with the changed resolution.\n",
        "index = 0;\n",
        "for i in imageNamesList:\n",
        "  j = i.rindex(\"/\")+1\n",
        "  img = Image.open(i)\n",
        "\n",
        "  ##Adding padding to the x-ray\n",
        "  width, height = img.size\n",
        "  top,left = 0,0\n",
        "\n",
        "  ##Checks the width and height\n",
        "  if width>height:\n",
        "    newHeight,newWidth = width,width\n",
        "    top = (int)((width-height)/2)\n",
        "  else:\n",
        "    newHeight,newWidth = height,height\n",
        "    left = (int)((height-width)/2)\n",
        "\n",
        "  ##Creates the new Image\n",
        "  result = Image.new(img.mode, (newWidth, newHeight))\n",
        "  result.paste(img,(left,top))\n",
        "\n",
        "  img = result.resize(size)\n",
        "\n",
        "  img.save(\"gdrive/MyDrive/Machine Learning 2021/train_images/RESIPAD224/\"+i[j:-4]+\"RESIPAD224.jpg\")\n",
        "  index = index+1\n",
        "\n",
        "  if (index % 100 == 0 ):\n",
        "    print(\"Finished no {} out of 4672\".format(index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtkJBtTnNyvE"
      },
      "source": [
        "####Importing the resized images filenames into a list for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhxFEqiiMemr"
      },
      "source": [
        "resizedImagesNameList = []\n",
        "imagePath=\"gdrive/MyDrive/Machine Learning 2021/train_images/RESIPAD224/\"\n",
        "for filename in glob.glob(imagePath+\"*.jpg\"):\n",
        "  resizedImagesNameList.append(filename)\n",
        "\n",
        "Image.open(resizedImagesNameList[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The following code is only used to test if the data transformation has been successful. The output should be a 224*224 2d array and the shape should also be (224,224)"
      ],
      "metadata": {
        "id": "EdHHXKZVVkwF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPTp8J6AOHLy"
      },
      "source": [
        "testImage = Image.open(resizedImagesNameList[2])\n",
        "testImageNumpy = np.array(testImage)\n",
        "\n",
        "#The output should be 224x224\n",
        "print (testImageNumpy.shape)\n",
        "\n",
        "print(testImageNumpy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrame = pd.read_csv(\"gdrive/MyDrive/Machine Learning 2021/labels_train.csv\")\n",
        "print(dataFrame.shape)"
      ],
      "metadata": {
        "id": "nC5keMF0bvmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkA4FxjPnwAh"
      },
      "source": [
        "x_train = np.zeros((4672,224*224))\n",
        "data = dataFrame.to_numpy()\n",
        "imagePath=\"gdrive/MyDrive/Machine Learning 2021/train_images/RESIPAD224/\"\n",
        "\n",
        "index=0\n",
        "for RSN in data:\n",
        "  path = imagePath+RSN[0][:-4]+\"RESIPAD224.jpg\"\n",
        "  testImage = Image.open(path).convert('L')\n",
        "  dummy = np.array(testImage)\n",
        "  print(\"%.2f\" % round(((index/4672)*100), 2),\"% done...\")\n",
        "  x_train[index]=dummy.flatten(order='C')\n",
        "  index+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqH6BkLwzTJ4"
      },
      "source": [
        "pd.DataFrame(exposable_train).to_csv(\"gdrive/MyDrive/Machine Learning 2021/x_train.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation 3.0\n",
        "We start with resizing the images into 336x336 instead of 224x224"
      ],
      "metadata": {
        "id": "_-qqbQm7LxJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Resizing each image into the size vector bellow\n",
        "```size=336,336```\n",
        "\n",
        "####Change the vector into your prefered size\n"
      ],
      "metadata": {
        "id": "nutRlW6zLvaO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao1O2QELL9Tv"
      },
      "source": [
        "size=336,336 ##We create a 2-index vector with our desired resolution for the pictures.\n",
        "\n",
        "##For each name we open the vanilla picture > resize it > save it with the changed resolution.\n",
        "for i in imageNamesList:\n",
        "  j = i.rindex(\"/\")+1\n",
        "  img = Image.open(i)\n",
        "  img = img.resize(size)\n",
        "  img.save(\"gdrive/MyDrive/Machine Learning 2021/train_images/RESIZED336/\"+i[j:-4]+\"RESIZED336.jpg\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NwmmULJMilO"
      },
      "source": [
        "resizedImagesNameList = []\n",
        "imagePath=\"gdrive/MyDrive/Machine Learning 2021/train_images/RESIZED336/\"\n",
        "for filename in glob.glob(imagePath+\"*.jpg\"):\n",
        "  resizedImagesNameList.append(filename)\n",
        "\n",
        "Image.open(resizedImagesNameList[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0C_6O6WMlxx"
      },
      "source": [
        "testImage = Image.open(resizedImagesNameList[2])\n",
        "testImageNumpy = np.array(testImage)\n",
        "\n",
        "#The output should be 336x336\n",
        "print (testImageNumpy.shape)\n",
        "\n",
        "print(testImageNumpy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrame = pd.read_csv(\"gdrive/MyDrive/Machine Learning 2021/labels_train.csv\")\n",
        "print(dataFrame.shape)"
      ],
      "metadata": {
        "id": "lMZ1JKzUMxJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5qd7G5TM0ak"
      },
      "source": [
        "x_train = np.zeros((4672,336*336))\n",
        "data = dataFrame.to_numpy()\n",
        "imagePath=\"gdrive/MyDrive/Machine Learning 2021/train_images/RESIZED336/\"\n",
        "\n",
        "index=0\n",
        "for RSN in data:\n",
        "  path = imagePath+RSN[0][:-4]+\"RESIZED336.jpg\"\n",
        "  testImage = Image.open(path).convert('L')\n",
        "  dummy = np.array(testImage)\n",
        "  print(\"%.2f\" % round(((index/4672)*100), 2),\"% done...\")\n",
        "  x_train[index]=dummy.flatten(order='C')\n",
        "  index+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1MZTZChM26U"
      },
      "source": [
        "pd.DataFrame(x_train).to_csv(\"gdrive/MyDrive/Machine Learning 2021/x_train_336.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Repeating the same actions for the test set"
      ],
      "metadata": {
        "id": "nBxPsJpfjnff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testImageNamesList = []\n",
        "imagePath=\"gdrive/MyDrive/Machine Learning 2021/test_images/test_images/\"\n",
        "index = 0\n",
        "for filename in glob.glob(imagePath+\"*.jpg\"):\n",
        "  ##Append the file paths on the list.\n",
        "  testImageNamesList.append(filename)\n",
        "  index = index+1\n",
        "  print(\"finished no {} of 1168\".format(index)) \n",
        "\n",
        "##Seting the starting index for a test drive\n",
        "i = testImageNamesList[1].rindex(\"/\")+1\n",
        "print(len(testImageNamesList))"
      ],
      "metadata": {
        "id": "WhSogewGjsti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4VN-b9pkteP"
      },
      "source": [
        "size=224,224 ##We create a 2-index vector with our desired resolution for the pictures.\n",
        "k = 0\n",
        "##For each name we open the vanilla picture > resize it > save it with the changed resolution.\n",
        "for i in testImageNamesList:\n",
        "  j = i.rindex(\"/\")+1\n",
        "  img = Image.open(i)\n",
        "  ##Adding padding to the x-ray\n",
        "  width, height = img.size\n",
        "  top,left = 0,0\n",
        "\n",
        "  ##Checks the width and height\n",
        "  if width>height:\n",
        "    newHeight,newWidth = width,width\n",
        "    top = (int)((width-height)/2)\n",
        "  else:\n",
        "    newHeight,newWidth = height,height\n",
        "    left = (int)((height-width)/2)\n",
        "\n",
        "  ##Creates the new Image\n",
        "  result = Image.new(img.mode, (newWidth, newHeight))\n",
        "  result.paste(img,(left,top))\n",
        "\n",
        "  img = result.resize(size)\n",
        "  img.save(\"gdrive/MyDrive/Machine Learning 2021/test_images/RESIPAD224/\"+i[j:-4]+\"RESIPAD224.jpg\")\n",
        "  k+=1\n",
        "\n",
        "  if (index % 100 == 0 ):\n",
        "    print(\"Finished no {} out of 4672\".format(k))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvS6tbg_nNrM"
      },
      "source": [
        "resizedImagesNameList = []\n",
        "imagePath=\"gdrive/MyDrive/Machine Learning 2021/test_images/RESIPAD224/\"\n",
        "for filename in glob.glob(imagePath+\"*.jpg\"):\n",
        "  resizedImagesNameList.append(filename)\n",
        "\n",
        "Image.open(resizedImagesNameList[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWPGwxWUnaWB"
      },
      "source": [
        "testImage = Image.open(resizedImagesNameList[2])\n",
        "testImageNumpy = np.array(testImage)\n",
        "\n",
        "#The output should be 224x224\n",
        "print (testImageNumpy.shape)\n",
        "\n",
        "print(testImageNumpy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbPoDEZJnns0"
      },
      "source": [
        "x_test = np.zeros(((1168,224,224)))\n",
        "imagePath=\"gdrive/MyDrive/Machine Learning 2021/test_images/RESIPAD224/\"\n",
        "\n",
        "for i in range(1168):\n",
        "  path = resizedImagesNameList[i]\n",
        "  testImage = Image.open(path).convert('L')\n",
        "  dummy = np.array(testImage)\n",
        "  print(\"%.2f\" % round(((i/1168)*100), 2),\"% done...\")\n",
        "  x_test[i]=dummy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_x_test = x_test.reshape(1168,224*224)\n",
        "\n",
        "pd.DataFrame(reshaped_x_test).to_csv(\"gdrive/MyDrive/Machine Learning 2021/x_test.csv\", index=False)"
      ],
      "metadata": {
        "id": "iXvgp2-HpGGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing the test data\n"
      ],
      "metadata": {
        "id": "Hnj4psr2shAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_x_test = pd.read_csv(\"gdrive/MyDrive/Machine Learning 2021/x_test.csv\").to_numpy()\n",
        "x_test = reshaped_x_test.reshape(((1168,224,224)))"
      ],
      "metadata": {
        "id": "jtl4n878q99m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Learning starts here\n"
      ],
      "metadata": {
        "id": "76HEmLrVm2kD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xRfunFp4Gum"
      },
      "source": [
        "dataFrame = pd.read_csv(\"gdrive/MyDrive/Machine Learning 2021/x_train_366_legit.csv\")\n",
        "x_train = dataFrame.to_numpy()\n",
        "print(x_train[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cell choice\n",
        "The first cell is before data augmentation\n",
        "The second cell if after data augmentation *2 times bigger"
      ],
      "metadata": {
        "id": "R8eJDt5q9bkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tempD = pd.read_csv(\"gdrive/MyDrive/Machine Learning 2021/labels_train.csv\")\n",
        "temp = tempD.to_numpy()\n",
        "y_train = np.int_(np.zeros(4672))\n",
        "for i in range(4672):\n",
        "  y_train[i] = temp[i][1]\n",
        "\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "PEtU-G9g9a7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNkFMaQALbfM"
      },
      "source": [
        "tempD = pd.read_csv(\"gdrive/MyDrive/Machine Learning 2021/labels_train.csv\")\n",
        "temp = tempD.to_numpy()\n",
        "y_train = np.int_(np.zeros(4672*2))\n",
        "\n",
        "for i in range(4672):\n",
        "  y_train[i] = temp[i][1]\n",
        "  y_train[4672+i] = y_train[i]\n",
        "  '''knowing that with data augmentation half of the files are the same but\n",
        "  flipped vertically, we are going to set the same label for each one of n-4672\n",
        "  of them'''\n",
        "\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data augmentation 1.0\n",
        "###Skip this if done once\n",
        "Here we are going to create 4672 more input data by flipping the pictures. Instead of actually flipping them we are going to mirror each 2 dimensional table and append it to the x_train numpy array."
      ],
      "metadata": {
        "id": "QN2DoLUMJ31M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###Data augmentation 1.0\n",
        "\n",
        "x_t = x_train.reshape(((4672,224,224)))\n",
        "\n",
        "x_train_2 = np.zeros(((4672*2,224,224)))\n",
        "\n",
        "b=4672\n",
        "for i in range(b):\n",
        "  x_train_2[i] = x_t[i]\n",
        "  for j in range(224):\n",
        "      x_train_2[b+i][j] = x_t[i][223-j]\n",
        "\n",
        "print(x_train_2[4672-1])\n",
        "print(x_train_2[4672*2-1])\n"
      ],
      "metadata": {
        "id": "zMs5zr3aJ3EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_x_train_2 = x_train_2.reshape(4672*2,224*224)\n",
        "\n",
        "pd.DataFrame(reshaped_x_train_2).to_csv(\"gdrive/MyDrive/Machine Learning 2021/x_train_2.csv\", index=False)"
      ],
      "metadata": {
        "id": "J-LYju9UN2Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWpDwO_g7hTl"
      },
      "source": [
        "print(x_train[:][:].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data augmentation 2.0\n",
        "I call this a data hyperbole where I change the nature of the data in order to see if it helps in training. (They are not readable as images)."
      ],
      "metadata": {
        "id": "ybA3FmiY-0qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(4672):\n",
        "  temp = x_train[i]*x_train[i] - (128*128)\n",
        "  x_train[i] = temp\n",
        "  print(\"finished {} out of 4672\".format(i))\n",
        "\n",
        "print(x_train)\n",
        "\n",
        "for i in range(1168):\n",
        "  temp = x_test[i]*x_test[i] - (128*128)\n",
        "  x_test[i] = temp\n",
        "  print(\"finished {} out of 1168\".format(i))"
      ],
      "metadata": {
        "id": "naCfbc1a9txJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data augmentation 3.1\n",
        "On this part we are going to use half a picture, each picture 4 times to train the network."
      ],
      "metadata": {
        "id": "EhXU099kfg2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_temp = np.zeros((4672*4))\n",
        "\n",
        "x_train_temp = np.zeros((4672*4,224*224))\n",
        "\n",
        "for i in range(4672):\n",
        "  ##Filling y_train\n",
        "  for j in range(3):\n",
        "    y_train_temp[i+j*4672] = y_train[i]\n",
        "  ##Filling x_train\n",
        "  ##No 1\n",
        "  temp = np.zeros((224,224))\n",
        "  for j in range(224):\n",
        "    for k in range(224):\n",
        "      temp[j][k] = x_train[j][k]\n",
        "  x_train_temp[i]=temp.reshape(224*224)\n",
        "  \n",
        "  ##No 2\n",
        "  temp = np.zeros((224,224))\n",
        "  for j in range(224):\n",
        "    for k in range(224):\n",
        "      temp[j][k] = x_train[j+111][k]\n",
        "  x_train_temp[i+4672] = temp.reshape(224*224)\n",
        "\n",
        "  #No 3\n",
        "  temp = np.zeros((224,224))\n",
        "  for j in range(224):\n",
        "    for k in range(224):\n",
        "      temp[j][k] = x_train[j][k+111]\n",
        "  x_train_temp[i+4672*2] = temp.reshape(224*224)\n",
        "\n",
        "  #No 4\n",
        "  temp = np.zeros((224,224))\n",
        "  for j in range(224):\n",
        "    for k in range(224):\n",
        "      temp[j][k] = x_train[j+111][k+111]\n",
        "  x_train_temp[i+4672*3] = temp.reshape(224*224)\n",
        "\n",
        "  print(\"Finished no {} out of {}\".format(i,4672))\n"
      ],
      "metadata": {
        "id": "B0sd3PWGfuFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(x_train_temp).to_csv(\"gdrive/MyDrive/Machine Learning 2021/x_train_366_legit.csv\", index=False)\n",
        "pd.DataFrame(y_train_temp).to_csv(\"gdrive/MyDrive/Machine Learning 2021/y_train_366_legit.csv\", index=False)"
      ],
      "metadata": {
        "id": "opCovPnW-txF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Delete previous created models!"
      ],
      "metadata": {
        "id": "ZRVhENhEw-WL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BbN6KEEVS4q"
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "try:\n",
        "    K.clear_session()\n",
        "    del model\n",
        "    print('Model deleted')\n",
        "except:\n",
        "    print('No model to delete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRIYzxEQNMe3"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers.core import Dense\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWD0a8SVVrY4"
      },
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "x_in = Input(shape=[224,224])\n",
        "x_flat = Flatten()(x_in)\n",
        "print(x_flat.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQmnTDacWJFt"
      },
      "source": [
        "dense_layer = Dense(268, activation='relu')\n",
        "y = dense_layer(x_flat) #First layer\n",
        "y = Dense(2048, activation='relu')(y) #Second layer\n",
        "y = Dense(1024, activation='relu')(y) #Third layer\n",
        "y = Dense(768, activation='relu') (y) #4rth layer\n",
        "#y = Dense(2048, activation='relu') (y) #4.5th layer\n",
        "y = Dense(512, activation='relu')(y) #5th layer\n",
        "out = Dense(3, activation='softmax') (y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5LAetoyWq9e"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#del model\n",
        "model = Model(inputs=x_in, outputs=out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRiXJCVAWlyo"
      },
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.000005),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x_train = reshaped_x_train_2\n",
        "x_t = x_train.reshape(((len(x_train),224,224)))\n",
        "#x_val = x_val.reshape((len(x_val),224,224))\n",
        "\n",
        "#print(x_t)\n",
        "\n",
        "print('x_train.shape = ', x_t.shape)\n",
        "print('y_train.shape = ', y_train.shape)\n",
        "print('x_test.shape = ', x_test.shape)"
      ],
      "metadata": {
        "id": "b304l5tPsNzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38YUU-GFPPV1"
      },
      "source": [
        "max_epochs = 73\n",
        "batch_size = 32 #64 is acceptable\n",
        "\n",
        "history = model.fit(x=x_t[584:], y=y_train[584:],\n",
        "                    validation_data=(x_t[:584],y_train[:584]),\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=max_epochs,\n",
        "                    verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Τα πέντε μηδενικά και το τελευταίο τάλιρο είναι μεγάλος αριθμός για learning rate για το νευρωνικό δίκτυο με τα συγκεκριμένα δεδομένα, προτείνται η μείωση του learning rate κατά 1/100"
      ],
      "metadata": {
        "id": "SZwH37WbPW0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a numpy 1d tensor filled with 0s.\n",
        "y_test = np.zeros(1168)\n",
        "\n",
        "#Predicting based on the current model.\n",
        "y_test_categorical = model.predict(x_test,verbose=1)"
      ],
      "metadata": {
        "id": "Z3km7kiCXMUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=0\n",
        "for i in y_test_categorical:\n",
        "  a,b,c = i\n",
        "  if a>b and a>c:\n",
        "    y_test[index] = 0\n",
        "  elif b>a and b>c:\n",
        "    y_test[index] = 1\n",
        "  elif c>a and c>b:\n",
        "    y_test[index] = 2\n",
        "  print(y_test[index])\n",
        "  index = index+1\n",
        "  \n"
      ],
      "metadata": {
        "id": "XVdnspAtYhcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using above second method to create a\n",
        "# 2D array\n",
        "rows, cols = (1168, 2)\n",
        "exported_predictions=[]\n",
        "for i in range(rows):\n",
        "    col = []\n",
        "    for j in range(cols):\n",
        "        col.append(0)\n",
        "    exported_predictions.append(col)\n",
        "\n",
        "for i in range(1168):\n",
        "  exported_predictions[i][0] = testImageNamesList[i][61:]\n",
        "  exported_predictions[i][1] = int(y_test[i])\n",
        "\n",
        "print(exported_predictions)"
      ],
      "metadata": {
        "id": "yIHdNJEv0DZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Saving n-st draft\n",
        "export = pd.DataFrame(exported_predictions)\n",
        "export.columns = ['file_name','class_id']\n",
        "\n",
        "export.to_csv(\"gdrive/MyDrive/Machine Learning 2021/y_test_DetERNET014.csv\", index=False)"
      ],
      "metadata": {
        "id": "gsMXcvGNzCri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##13/12/2021\n",
        "The weights multiplier is useless because the result of having the same architecture in layers with the number of parameteers being c1,c2,c3)*n with the same amount of epochs and learning rate, the result in trainset was the exact same. It could be coinsidense or it could be because of the same architecture it just divides each parameter into n parameters.\n",
        "\n",
        "The 2^m^n approach of mlp managed to succeed at 76% train accuracy. with the worst score being at 72%. The next apporach is to reverse the input data in order to increase the amount of input images from 4,6k to 9,2k."
      ],
      "metadata": {
        "id": "eWURAHO278_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###16/12/2021\n",
        "As a part 2, I am going to save the resized images in a 336*336 size.<br>"
      ],
      "metadata": {
        "id": "Q9xOX5TuLG5L"
      }
    }
  ]
}